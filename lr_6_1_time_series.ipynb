{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNiQcEJb5Ic2"
   },
   "source": [
    "# Time Series\n",
    "\n",
    "In this problem, you will be analyzing and visualizing time-series data. Specifically, you will be working with Pittsburgh Port Authority's TrueTime data which is [publicly available](http://truetime.portauthority.org/bustime/login.jsp). If you're interested, you can request an API key and collect the data yourself, but we've already collected a subset of the available data for the purpose of this assignment.\n",
    "\n",
    "We will be using [`pandas`](https://pandas.pydata.org/pandas-docs/stable/user_guide/) to work with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sp0U27gW5IdF"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFj71k1Y5IdJ"
   },
   "source": [
    "## TrueTime dataset\n",
    "\n",
    "The bus data has been collected by querying the TrueTime API every minute. Each time, we make a request for vehicle information for every bus running on the 61A, 61B, 61C, and 61D bus routes. The results are given as XML, which we then parsed and stored within the `vehicles` table of a [sqlite](https://www.sqlite.org/index.html) database. (Ignore other tables in the database.)\n",
    "\n",
    "| column | data | \n",
    "| --- | --- |\n",
    "| vid      | vehicle identifier |\n",
    "| tmstmp | date and time of the last positional update of the vehicle |\n",
    "| lat | latitude position of the vehicle in decimal degrees |\n",
    "| lon | longitude position of the vehicle in decimal degrees |\n",
    "| hdg | heading of vehicle as a 360 degree value (0 is north, 90 is east, 180 is south, and 270 is west |\n",
    "| pid | pattern ID of trip currently being executed | \n",
    "| rt | route that is currently being executed | \n",
    "| des | destination of the current trip | \n",
    "| pdist | linear distance (feet) vehicle has traveled into the current pattern |\n",
    "| spd | speed as reported from the vehicle in miles per hour | \n",
    "| tablockid | TA's version of the scheduled block identifier for work currently behind performed |\n",
    "| tatripid | TA's version of the scheduled trip identifier for the vehicle's current trip |\n",
    "\n",
    "First, you will need to read in the data. We have dumped the raw form of the data into a sqlite database, which you can read directly into a pandas dataframe using `pd.read_sql_query`. You need to read the data in and do this:\n",
    "\n",
    "1. Sometimes the TrueTime API returns a bogus result that has empty strings for the `vid`. You should remove all rows that have blank `vid`s. \n",
    "2. SQLite does not enforce types on the data, so pandas reads most columns as objects even if the underlying type is an integer or float. To run numerical functions on them you need to convert numeric columns to the correct type.\n",
    "3. You need to set the timestamps as `pd.DatetimeIndex` and set them to be the Dataframe index. (You may need to wrap the type conversion like this `... = pd.DatetimeIndex(...)` to make it work.) Pandas will prepare the data for efficient time-based querying accordingly. You also need to retain the original additional `tmstmp` column.\n",
    "\n",
    "Note that strings show up as objects. This is because the underlying implementation of Pandas uses numpy arrays, which need fixed-size entries, so they store pointers to strings instead of the strings themselves.  The types of your dataframes columns should match the datatypes in the first test case, namely\n",
    "\n",
    "```python\n",
    "{'vid': 'int64',\n",
    " 'tmstmp': 'datetime64[ns]',\n",
    " 'lat': 'float64',\n",
    " 'lon': 'float64',\n",
    " 'hdg': 'int64',\n",
    " 'pid': 'int64',\n",
    " 'rt': 'object',\n",
    " 'des': 'object',\n",
    " 'pdist': 'int64',\n",
    " 'spd': 'int64',\n",
    " 'tablockid': 'object',\n",
    " 'tatripid': 'int64'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cNvGuDrK5IdN",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def load_data():\n",
    "    \"\"\" Read the sqlite database, from the file \"bus_aug23.db\" into a pandas dataframe\n",
    "    Returns:\n",
    "        pd.DataFrame : a dataframe with the vehicle data \n",
    "    \"\"\"    \n",
    "    try:\n",
    "        conn = sqlite3.connect(\"bus_aug23.db\")\n",
    "\n",
    "        query = \"SELECT * FROM vehicles;\"\n",
    "        data = pd.read_sql_query(query, conn)\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaZSn2_Y5IdX"
   },
   "source": [
    "## Splitting Data by Vehicle\n",
    "\n",
    "Now that the data is loaded, we will split the `vehicle` dataframe into dataframes for each individual vehicle. (Note that the same vehicle will run different routes at different times; this is expected behavior.)\n",
    "\n",
    "You use the [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) feature of pandas to (as the name suggests) group the dataframe by the `vid`  field. Convert the result into a list-of-dataframes.\n",
    "\n",
    "Note that `groupby` doesn't create a copy of the underlying data. Instead, it creates a new dataframe that points to some rows within the original data; this is vastly more memory-efficient especially when working with image or video data. We also include a test to make sure you didn't accidentally copy it.\n",
    "\n",
    "We strongly suggest you read the [`split-apply-combine` pattern](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html) guide; that is a powerful pattern that we will be using repeatedly in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWg3Ec6L5IdY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_vehicles(df):\n",
    "    \"\"\" Splits the dataframe into a list of dataframes for each individual vehicle. \n",
    "    Args: \n",
    "        df (pd.DataFrame): A dataframe containing all data\n",
    "        \n",
    "    Returns: \n",
    "        (list): A list of dataframes, where each dataframe contains vehicle data for a single vehicle\n",
    "    \"\"\"\n",
    "    grouped = df.groupby('vid')\n",
    "    vehicle_dfs = [group.copy() for _, group in grouped]\n",
    "\n",
    "    return vehicle_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiakup4k5Ide"
   },
   "source": [
    "## Visualizing Speeds over Time\n",
    "\n",
    "Great! Now that we are all warmed up, let's try to extract some more information from this dataset. We want to see if traffic is slower at some times during the day than others.\n",
    "\n",
    "We can't directly measure the speed of traffic using the dataset, but we can infer this from the average speed of each bus (which we assume depends on the speed of traffic). We begin by writing a function that:\n",
    "\n",
    "1. selects all entries lying between `time_start` and `time_end` (inclusive) on any day within that,\n",
    "2. selects only data that falls on weekdays,\n",
    "3. groups entries by `vid`, and\n",
    "4. calculates the mean speed for each group\n",
    "\n",
    "The output should be a Series with the index `vid` (vehicle id) and the value `spd`, which is the mean recorded speed for each `vid` in the time range on any weekday in the dataset.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "1. Remember when we set the index to be a DatetimeIndex? This allows you to use [special lookup functions](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#reindexing-selection-label-manipulation).\n",
    "2. We only want the data where `dayofweek < 5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bU-qELfa5Idf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_speeds(df, time_start, time_end):\n",
    "    \"\"\" Splits the dataframe of vehicle data into a list of dataframes for each individual trip. \n",
    "    \n",
    "    Args: \n",
    "        df (pd.DataFrame): A dataframe containing vehicle data\n",
    "        \n",
    "    Returns: \n",
    "        (list): A list of dataframes, where each dataframe contains vehicle data for a single trip\n",
    "    \"\"\"\n",
    "    df['tmstmp'] = pd.to_datetime(df['tmstmp'])\n",
    "    df = df.set_index('tmstmp')\n",
    "\n",
    "    df_time_filtered = df.between_time(time_start, time_end)\n",
    "    df_weekday_filtered = df_time_filtered[df_time_filtered.index.dayofweek < 5]\n",
    "    return df_weekday_filtered.groupby('vid')['spd'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3VWcnfU5Idk"
   },
   "source": [
    "Now that we have that function, let's visualize it as a heatmap! The x-axis represents time-of-day, from 00:00am to 11:59pm, with a step size defined by `period`. The y-axis represents average speed in bins defined by `speed_bins`. The value of each cell corresponds to the number of buses reaching that speed in the time window.  You can call the function as follows:\n",
    "\n",
    "```\n",
    "plot = visualize_speeds(df, pd.period_range(start='12:00am', end='11:59pm', freq=\"15T\"), \n",
    "                        list(range(0, 50, 2)))\n",
    "```\n",
    "which will plot an image like the following:\n",
    "![](plot.png)\n",
    "Note that you don't need to actually set all the correct plot labels, etc, in order to pass the tests for this question: you simply need to call `plt.imshow()` on an array that represents this same data (and the tests, e.g. all just test the values/size in the internal array).\n",
    "\n",
    "*Note*: the `freq` parameter above uses strings with [offset aliases for pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "48gcduml5Idl"
   },
   "outputs": [],
   "source": [
    "def visualize_speeds(df, period, speed_bins):\n",
    "    \"\"\"Plot a heatmap of speeds, with x axis being the number of \n",
    "    \n",
    "    Args: \n",
    "        df (pd.DataFrame): A dataframe containing vehicle data\n",
    "        period (pd.PeriodIndex): A period index giving a list of time intervals to plot, constructed\n",
    "                                 using the pd.period_range() function\n",
    "        speed_bins (list): A list of bins of speed values to bin within each time interval\n",
    "        \n",
    "    Returns: \n",
    "        (matplotlib.AxesImage): Result of plt.imshow() on the heatmap array\n",
    "    \"\"\"\n",
    "    df['tmstmp'] = pd.to_datetime(df['tmstmp'])\n",
    "    df = df.set_index('tmstmp')\n",
    "\n",
    "    heatmap = np.zeros((len(speed_bins) - 1, len(period)))\n",
    "\n",
    "    for i, time_bin in enumerate(period):\n",
    "        start_time = time_bin.start_time\n",
    "        end_time = time_bin.end_time\n",
    "        df_time_filtered = df.between_time(start_time.time(), end_time.time())\n",
    "        speed_counts, _ = np.histogram(df_time_filtered['spd'], bins=speed_bins)\n",
    "        heatmap[:, i] = speed_counts\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    img = ax.imshow(heatmap, aspect='auto', origin='lower',\n",
    "                    extent=[0, len(period), speed_bins[0], speed_bins[-1]],\n",
    "                    cmap='viridis')\n",
    "\n",
    "    fig.colorbar(img, ax=ax, label=\"Number of Buses\")\n",
    "\n",
    "    plt.savefig(\"visualize_speeds.png\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJl4RCFg5Idp"
   },
   "source": [
    "We can see a clear dip in speed from 15:00--18:00; that's the evening rush hour. The average speed improves as it gets later in the evening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mIeHAXI5Idp"
   },
   "source": [
    "## Visualizing Bus Bunching\n",
    "\n",
    "That's interesting, but not exactly useful. Let's apply this to a real-world problem: [Bus Bunching](https://en.wikipedia.org/wiki/Bus_bunching), where buses on similar routes tend to clump together, reducing the tail performance of the travel network.\n",
    "\n",
    "Buses on the same route and direction have the same `pid` (pattern id) and their progress along the route is given by `pdist`.  We thus want to find the closest distance between two buses at the same time, on the same `pid`, but with different `vid` (this corresponds to the distance between two different buses on the same route ... the lower this quantity then the closer the buses are bunched).\n",
    "\n",
    "We'll do this by:\n",
    "1. Grouping the data by `pid`, 10-minute blocks, and then by the bus (i.e. `vid`) \n",
    "2. Calculating the average `pdist` value for each bus\n",
    "3. Computing the _smallest_ difference between `pdist` values for each different vehicle within a (`pid`, 10 min block) grouping.  Drop elements with only one vehicle within the grouping.\n",
    "\n",
    "We'll begin by doing the first three steps.\n",
    "\n",
    "Here are some tips and potential pitfalls:\n",
    "\n",
    "- Perform the grouping first by `pid`, then by time, and then by the bus `vid`. This can be done in a single call to `groupby`.\n",
    "- Look at `pandas.Grouper` to help you group by time\n",
    "- To perform step three, _regroup_ the data just by (`pid`, `tmstmp`) and then use `groupby().apply()` to compute the smallest difference in `pdists` within different vehicles in this group.  You can find the smallest differene between elements in an array by taking sorting the entries and taking the minimum difference value (to drop cases with only one vehicle, your `apply()` function can return NaN for these cases, then subsequently drop NaN rows).\n",
    "- As indicated by the test case, after dropping all NaN values (groups with only one bus for that `pid` in that time frame), you should have 7601 records.\n",
    "- This is overall a challenging problem, but the resulting code can be quite short (if written compactly).  For reference, our solution is 3 lines of (albeit somewhat dense) pandas code and runs in about 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QzoLl2F5Idp"
   },
   "outputs": [],
   "source": [
    "def closest_pdist(vdf):\n",
    "    \"\"\"calculate the mean pdist value \n",
    "    \n",
    "    params:\n",
    "        vdf : pd.Dataframe -- the loaded dataframe\n",
    "        \n",
    "    returns: pd.Series with indices:\n",
    "        - `pid`   : the pattern id\n",
    "        - `tmstmp`: the time, grouped to 10-minute blocks\n",
    "        and value equal to the minimum difference in pdist values for vehicles on this pid, at this time\n",
    "    \"\"\"\n",
    "    grouped = vdf.groupby(\n",
    "        ['pid', pd.Grouper(key='tmstmp', freq='10min'), 'vid']\n",
    "    )['pdist'].mean().reset_index()\n",
    "    regrouped = grouped.groupby(['pid', 'tmstmp'])['pdist']\n",
    "\n",
    "    return regrouped.apply(\n",
    "        lambda group: group.sort_values().diff().iloc[1:].min()\n",
    "        if len(group) > 1 else None\n",
    "    ).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBCagPP15Idq"
   },
   "source": [
    "Once you've completed this portion, you can visualize the bunching patterns in a few different ways (telling is the fact that there are several instances of two buses essentially being in the exact same location within ~100 feet of each other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p199zUun5Idr"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m,\u001B[38;5;241m5\u001B[39m))\n\u001B[1;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39msemilogy(closest_pdist(load_data())\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;241m4522\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbx\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.semilogy(closest_pdist(load_data()).loc[4522], 'bx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0uXO-8tw5Idr"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mxscale(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mhist(closest_pdist(load_data())\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;241m4522\u001B[39m], bins\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mlogspace(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m30\u001B[39m));\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.xscale(\"log\")\n",
    "plt.hist(closest_pdist(load_data()).loc[4522], bins=np.logspace(0,5,30));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
