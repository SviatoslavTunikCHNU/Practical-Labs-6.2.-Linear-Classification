{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb0Tr85SYAd5"
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "In this labs, we are going to apply linear regression to the problem of predicting developer satisfaction based upon information about their careers, from a StackOverflow survey.  The data from this question is based on the [2019 StackOverflow Survey](https://insights.stackoverflow.com/survey/2019); accordingly, the subset bundled with this assignment is also released under the Open Database License (ODbL) v1.0.  For this problem, you should not use Scikit-Learn, but instead, implement all the least squares solutions manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsSSM7jXYAeC"
   },
   "source": [
    "### Q1 Data Parsing\n",
    "\n",
    "The data from this survey has the values as described below.  Your eventual goal will be to predict (a numerical equivalent of) the `CarreerSat` column, indicating how satisfied the subject is with their career), based upon the other values.  Note that because the career satisfaction values are ordinal, we likely should not be predicting them with linear regression, but as an illustrative example, this is still a reasonable task.\n",
    "\n",
    "The data set contains the following columns.\n",
    "\n",
    "| Column | Sample | Does/is the respondent... | Type/Values |\n",
    "| --- |:--- |:--- |:--- |\n",
    "| **CareerSat** | 'vs' | satisfied with their career? | (`vd`, `sd`, `ne`, `NA`, `ss`, `vs`) -- corresponding to ({very, slightly}, {satisfied, dissatisfied}), neutral, and not applicable |\n",
    "| MgrWant | 'n' | ...want to be a manager? | boolean |\n",
    "| Age    | '22'   | age | integer     |\n",
    "| CodeRevHrs | '2' | hours a week spent reviewing code | integer |\n",
    "| ConvertedComp | '61000' | yearly compensation in 2019 USD | integer |\n",
    "| Country | 'United States' | lives in country | string _(ignore in regression)_ |\n",
    "| Dependents | 'n' | ...have children or other dependents. | boolean |\n",
    "| DevEnvironVSC | 'y' | ...use Visual Studio Code | boolean |\n",
    "| DevTypeFullStack | 'n' | ...identify as a full-stack developer | boolean |\n",
    "| EdLevel | 'bachelors' | maximum education level | (`other`, `bachelors`, `masters`, `doctoral`) |\n",
    "| EduOtherMOOC | 'y' | ...ever taken a Massively Open Online Course | boolean |\n",
    "| EduOtherSelf | 'y' | ...ever taught themselves a new platform | boolean _(ignore in regression, this is  duplicate field)_ |\n",
    "| Extraversion | 'y' | ...prefer in-person meetings to online meetings | boolean |\n",
    "| GenderIsMan | 'y' | ...male | boolean |\n",
    "| Hobbyist | 'n' | ...write code as a hobby? | boolean |\n",
    "| MgrIdiot | 'very' | ...think their manager knows what they are doing? | (`NA`, `not`, `some`, `very`), in order of increasing confidence |\n",
    "| OpSys | 'win' | which OS do they use? | (`win`, `mac`, `tux`, `NA`), for (Windows, Mac OSX, Linux-like, NA) |\n",
    "| OpenSourcer | 'Never' | ...contribute to open-source projects? | (`never`, `year`, `month-year`, `month`), in increasing order of frequency |\n",
    "| OrgSize | '100-499' | number of employees in organization? | (`NA`, `1`, `2-9`, `10-19`, `20-99`, `100-499`, `500-999`, `1,000-4,999`, `5,000-9,999`, `10,000+`) |\n",
    "| Respondent | '4' | respondent ID from original data | integer _(ignore in regression)_ |\n",
    "| Student | 'n' | ...currently a student? | boolean |\n",
    "| UndergradMajorIsComputerScience | 'y' | ...majored in CS? | boolean |\n",
    "| UnitTestsProcess | 'n' | ...use unit tests in their job? | boolean |\n",
    "| WorkWeekHrs | '40' | hours a week worked | integer |\n",
    "| YearsCode | 3 | years since first programming | integer |\n",
    "| YearsCodePro | 0 | years programming professionally | integer |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIaLMH-GYAeG"
   },
   "source": [
    "When you load the data for linear regression, you will want to convert each type to a floating point value according to the columns above.  Specifically, for each column listed above, convert the value to a numeric quantity using the rules below.  Note that there are some fairly unnatural assumptions here (like converting NAs to 0.0), but these are largely to illustrate the methodology without adding too much additional processing work.\n",
    "\n",
    " - _boolean_ : `y`/`NA`/`n` assigned to `+1.0`/`0.0`/`0.0`\n",
    " - _integer_ : convert to `float`, preserving value. `NA` equals `0.0`. \n",
    " - _string_ : not included in regression; we'll use it later\n",
    " - CareerSat: Map (`vd`, `sd`, `ne`, `NA`, `ss`, `vs`) to (-2.0, -1.0, 0.0, 0.0, 1.0, 2.0)\n",
    " - EdLevel: Map (`other`, `bachelors`, `masters`, `doctoral`) to (0.0, 1.0, 1.5, 2.0)\n",
    " - MgrIdiot: Map (`NA`, `not`, `some`, `very`) to (-1.0, -1.0, 0.0, 1.0)\n",
    " - OpSys: Map (`win`, `mac`, `NA`, `tux`, `BSD`) to (-1.0, 0.0, 0.0, 1.0, 1.0)\n",
    " - OpenSourcer : Map (`never`, `year`, `month-year`, `month`) to (0.0, 0.5, 1.0, 2.0)\n",
    " - OrgSize: Map each range \"$a$-$b$\" to the value $ln(a)$. Treat `NA` as `ln(1.0) = 0`. We are converting an exponentially distributed range to a linearly distributed one.\n",
    "\n",
    "Remove the columns listed above as being ignored. \n",
    "\n",
    "Some hints:\n",
    "  1. Load the csv file with `pd.read_csv(filname, dtype=str, keep_default_na=False)` to ensure that you load all columns as text (so you can do your own preprocessing), and ignore pandas's default conversion to NaN values.\n",
    "  2. Use the `.apply()` function in pandas to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLu0XmT1YAeI"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import math\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uzLmJbJYAeK"
   },
   "outputs": [],
   "source": [
    "def parse_stackoverflow_data():\n",
    "    \"\"\"Load data from the \"eggs.csv.gz\" file, and convert for use in linear regression\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame, containing the data converted to floating point values appropriately.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"eggs.csv.gz\", dtype=str, keep_default_na=False)\n",
    "\n",
    "    def convert_boolean(value):\n",
    "        return 1.0 if value == 'y' else 0.0\n",
    "\n",
    "    def convert_integer(value):\n",
    "        return float(value) if value.isdigit() else 0.0\n",
    "\n",
    "    career_sat_map = {'vd': -2.0, 'sd': -1.0, 'ne': 0.0, 'NA': 0.0, 'ss': 1.0, 'vs': 2.0}\n",
    "\n",
    "    def convert_careersat(value):\n",
    "        return career_sat_map.get(value, 0.0)\n",
    "\n",
    "    edlevel_map = {'other': 0.0, 'bachelors': 1.0, 'masters': 1.5, 'doctoral': 2.0}\n",
    "\n",
    "    def convert_edlevel(value):\n",
    "        return edlevel_map.get(value, 0.0)\n",
    "\n",
    "    mgr_idiot_map = {'NA': -1.0, 'not': -1.0, 'some': 0.0, 'very': 1.0}\n",
    "\n",
    "    def convert_mgridiot(value):\n",
    "        return mgr_idiot_map.get(value, -1.0)\n",
    "\n",
    "    opsys_map = {'win': -1.0, 'mac': 0.0, 'NA': 0.0, 'tux': 1.0, 'BSD': 1.0}\n",
    "\n",
    "    def convert_opsys(value):\n",
    "        return opsys_map.get(value, 0.0)\n",
    "\n",
    "    opensourcer_map = {'never': 0.0, 'year': 0.5, 'month-year': 1.0, 'month': 2.0}\n",
    "\n",
    "    def convert_opensourcer(value):\n",
    "        return opensourcer_map.get(value, 0.0)\n",
    "\n",
    "    def convert_orgsize(value):\n",
    "        if value == 'NA':\n",
    "            return 0.0\n",
    "        try:\n",
    "            lower_bound = float(value.split('-')[0].replace('$', '').replace(',', '').strip())\n",
    "            return math.log(lower_bound)\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "\n",
    "    columns_int = ['Age', 'CodeRevHrs', 'ConvertedComp', 'WorkWeekHrs', 'YearsCode', 'YearsCodePro']\n",
    "    columns_boolean = ['MgrWant', 'Dependents', 'DevEnvironVSC', 'DevTypeFullStack', 'EduOtherMOOC', 'Extraversion', 'GenderIsMan', 'Hobbyist', 'Student', 'UndergradMajorIsComputerScience', 'UnitTestsProcess']\n",
    "\n",
    "    for column in columns_boolean:\n",
    "        df[column] = df[column].apply(convert_boolean)\n",
    "    for column in columns_int:\n",
    "        df[column] = df[column].apply(convert_integer)\n",
    "\n",
    "    df['CareerSat'] = df['CareerSat'].apply(convert_careersat)\n",
    "    df['EdLevel'] = df['EdLevel'].apply(convert_edlevel)\n",
    "    df['MgrIdiot'] = df['MgrIdiot'].apply(convert_mgridiot)\n",
    "    df['OpSys'] = df['OpSys'].apply(convert_opsys)\n",
    "    df['OpenSourcer'] = df['OpenSourcer'].apply(convert_opensourcer)\n",
    "    df['OrgSize'] = df['OrgSize'].apply(convert_orgsize)\n",
    "\n",
    "    ignored_columns = ['Country', 'EduOtherSelf', 'Respondent']\n",
    "    df = df.drop(columns=ignored_columns, errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rJW5Um0YAeT"
   },
   "source": [
    "### Q2 Splitting Data\n",
    "\n",
    "Now we prepare the converted data for regression. In this step, we:\n",
    "\n",
    " 1. Extract the data as a numpy array\n",
    " 2. Split the data into train and validation sets.  You can use the first 20% of the data (rounded down) as the validation set and keep the remaining as the training set. (Note that it is common practice to randomize the dataset; this has already been done. Don't shuffle the dataset for this assignment.)\n",
    " 3. Split each set into the predicted column (the first column in the data frame) and the feature columns (the remaining columns), plus a final column corresponding to a constant 1.0 value.  Not that you should keep the ordering of the feature columns the same as they appear in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wuwKKD3YAeU"
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    \"\"\"split the data into training and validation sets, and convert them to np.ndarray. (Step 1 and 2 above.)\n",
    "\n",
    "    args:\n",
    "        df : pandas.DataFrame -- the parsed data, as returned by parse_stackoverflow_data()\n",
    "\n",
    "    returns: X_train, y_train, X_val, y_val\n",
    "      X_train  : np.ndarray -- the second 80% of the data features\n",
    "      y_train : np.ndarray -- the second 80% of the target values\n",
    "      X_val : np.ndarray -- the first 20% (rounded down) of the data features\n",
    "      y_val : np.ndarray -- the first 20% of the target valuesn\n",
    "    \"\"\"\n",
    "    split_idx = len(df) // 5\n",
    "    val_set = df.iloc[:split_idx]\n",
    "    train_set = df.iloc[split_idx:]\n",
    "    y_val = val_set.iloc[:, 0].to_numpy()\n",
    "    X_val = val_set.iloc[:, 1:].to_numpy()\n",
    "\n",
    "    y_train = train_set.iloc[:, 0].to_numpy()\n",
    "    X_train = train_set.iloc[:, 1:].to_numpy()\n",
    "\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdDS-CxBYAec"
   },
   "source": [
    "### Q3 Linear Regression\n",
    "\n",
    "Now we are going to build a simple scikit-learn-like class for least squares linear regression.  Recall from lecture that the linear regression approach models the data as:\n",
    "$$ y^{(i)} \\approx \\theta^T x^{(i)} $$\n",
    "and the optimal $\\theta$ is given by:\n",
    "$$ \\theta^* = (X^T X)^{-1}X^T y $$\n",
    "using the notation described in the slides and course notes.  Recall, as mentioned in class, that you should use the `np.linalg.solve()` function rather than the `np.linalg.inv()` function to compute this solution.\n",
    "\n",
    "Implement the class below, plus the `squared_error` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VKh1SDVYAec"
   },
   "outputs": [],
   "source": [
    "def squared_error(y_pred, y):\n",
    "    \"\"\" Utility function to compute squared error\n",
    "    args:\n",
    "        y_pred : np.ndarray[num_examples] -- the predictions\n",
    "        y : np.ndarray[num_examples] -- the ground truth values\n",
    "\n",
    "    returns:\n",
    "        float : _average_ squared error between y_pred and y\n",
    "    \"\"\"\n",
    "    return np.mean((y_pred - y) ** 2)\n",
    "    \n",
    "class LinearRegression():\n",
    "    \"\"\" Perform linear regression and predict the output on unseen examples. \n",
    "    \n",
    "    attributes: \n",
    "        theta (np.ndarray) : vector containing parameters for the features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        X_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        self.theta = np.linalg.solve(X_bias.T @ X_bias, X_bias.T @ y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        return X_bias @ self.theta\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R26vwwiyYAfG"
   },
   "source": [
    "## Q4 Evaluation versus baselines\n",
    "\n",
    "As a final consideration, If you implement this properly, you will see that we get a squared error of around 1.3 on the validation set.  Is this \"good\"?  This is one of the more subtle points of many data science problems, but we can start to get some sense of this by looking at what the predictions would look like if we _just_ predicted the mean target output on the training set (this is essentially the \"simplest\" prediction we could make if we didn't look at the features at all).\n",
    "\n",
    "Implement the following function to evaluate our linear regression.  Think about what this signifies about the quality of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iekxW7-YAfH"
   },
   "outputs": [],
   "source": [
    "def evaluate_linear_regression(X_train, y_train, X_val, y_val):\n",
    "    \"\"\" Evaluate the squared error of linear regression versus the simple mean-prediciton baseline.\n",
    "    \n",
    "    Args: X_train, y_train, X_val, y_val -- output of split_data() function\n",
    "    \n",
    "    Return: Tuple[validation_mse, baseline_mse]:\n",
    "        validation_mse: float -- squared error of predictions on validation set, when training on training set\n",
    "        baseline_mse: float -- squared error of predicting the mean on the training set\"\"\"\n",
    "    model = LinearRegression(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    validation_mse = squared_error(y_pred, y_val)\n",
    "    y_train_mean = np.mean(y_train)\n",
    "    baseline_mse = squared_error(np.full_like(y_val, y_train_mean), y_val)\n",
    "\n",
    "    return validation_mse, baseline_mse"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
